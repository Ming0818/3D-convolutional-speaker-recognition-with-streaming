{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import re\n",
    "import sys\n",
    "\n",
    "from google.cloud import speech\n",
    "from google.cloud.speech import enums\n",
    "from google.cloud.speech import types\n",
    "import pyaudio\n",
    "from six.moves import queue\n",
    "# [END import_libraries]\n",
    "\n",
    "# Audio recording parameters\n",
    "RATE = 16000\n",
    "CHUNK = int(RATE / 10)  # 100ms\n",
    "\n",
    "\n",
    "class MicrophoneStream(object):\n",
    "    \"\"\"Opens a recording stream as a generator yielding the audio chunks.\"\"\"\n",
    "    def __init__(self, rate, chunk):\n",
    "        self._rate = rate\n",
    "        self._chunk = chunk\n",
    "\n",
    "        # Create a thread-safe buffer of audio data\n",
    "        self._buff = queue.Queue()\n",
    "        self.closed = True\n",
    "\n",
    "    def __enter__(self):\n",
    "        print \"enter\"\n",
    "        self._audio_interface = pyaudio.PyAudio()\n",
    "        self._audio_stream = self._audio_interface.open(\n",
    "            format=pyaudio.paInt16,\n",
    "            # The API currently only supports 1-channel (mono) audio\n",
    "            # https://goo.gl/z757pE\n",
    "            channels=1, rate=self._rate,\n",
    "            input=True, frames_per_buffer=self._chunk,\n",
    "            # Run the audio stream asynchronously to fill the buffer object.\n",
    "            # This is necessary so that the input device's buffer doesn't\n",
    "            # overflow while the calling thread makes network requests, etc.\n",
    "            stream_callback=self._fill_buffer,\n",
    "        )\n",
    "\n",
    "        self.closed = False\n",
    "\n",
    "        return self\n",
    "\n",
    "    def __exit__(self, type, value, traceback):\n",
    "        print \"exit\"\n",
    "        self._audio_stream.stop_stream()\n",
    "        self._audio_stream.close()\n",
    "        self.closed = True\n",
    "        # Signal the generator to terminate so that the client's\n",
    "        # streaming_recognize method will not block the process termination.\n",
    "        self._buff.put(None)\n",
    "        self._audio_interface.terminate()\n",
    "\n",
    "    def _fill_buffer(self, in_data, frame_count, time_info, status_flags):\n",
    "        \"\"\"Continuously collect data from the audio stream, into the buffer.\"\"\"\n",
    "        self._buff.put(in_data)\n",
    "        return None, pyaudio.paContinue\n",
    "\n",
    "    def generator(self):\n",
    "        while not self.closed:\n",
    "            # Use a blocking get() to ensure there's at least one chunk of\n",
    "            # data, and stop iteration if the chunk is None, indicating the\n",
    "            # end of the audio stream.\n",
    "            chunk = self._buff.get()\n",
    "            if chunk is None:\n",
    "                return\n",
    "            data = [chunk]\n",
    "\n",
    "            # Now consume whatever other data's still buffered.\n",
    "            while True:\n",
    "                try:\n",
    "                    chunk = self._buff.get(block=False)\n",
    "                    if chunk is None:\n",
    "                        return\n",
    "                    data.append(chunk)\n",
    "                except queue.Empty:\n",
    "                    break\n",
    "            print len(data)\n",
    "\n",
    "            yield b''.join(data)\n",
    "            \n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "enter\n",
      "1\n",
      "exit\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'astype'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-9bec25a09803>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mcontent\u001b[0m \u001b[0;32min\u001b[0m \u001b[0maudio_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         mfcc = speechpy.feature.mfcc(content, sampling_frequency=1600, frame_length=0.020, frame_stride=0.01,\n\u001b[0;32m----> 6\u001b[0;31m              num_filters=40, fft_length=512, low_frequency=0, high_frequency=None)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/speechpy/feature.pyc\u001b[0m in \u001b[0;36mmfcc\u001b[0;34m(signal, sampling_frequency, frame_length, frame_stride, num_cepstral, num_filters, fft_length, low_frequency, high_frequency, dc_elimination)\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     feature, energy = mfe(signal, sampling_frequency=sampling_frequency, frame_length=frame_length, frame_stride=frame_stride,\n\u001b[0;32m---> 78\u001b[0;31m              num_filters=num_filters, fft_length=fft_length, low_frequency=low_frequency, high_frequency=high_frequency)\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeature\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_cepstral\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/speechpy/feature.pyc\u001b[0m in \u001b[0;36mmfe\u001b[0;34m(signal, sampling_frequency, frame_length, frame_stride, num_filters, fft_length, low_frequency, high_frequency)\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m     \u001b[0;31m# Convert to float\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0msignal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msignal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;31m# Stack frames\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'astype'"
     ]
    }
   ],
   "source": [
    "import speechpy\n",
    "with MicrophoneStream(RATE, CHUNK) as stream:\n",
    "    audio_generator = stream.generator()\n",
    "    for content in audio_generator:\n",
    "        mfcc = speechpy.feature.mfcc(content, sampling_frequency=1600, frame_length=0.020, frame_stride=0.01,\n",
    "             num_filters=40, fft_length=512, low_frequency=0, high_frequency=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23 18 64 ..., -2  2 -3]\n",
      "<type 'numpy.ndarray'>\n",
      "(528038,)\n",
      "44100\n",
      "(1197, 882)\n",
      "('power spectrum shape=', (1197, 257))\n",
      "('mfcc(mean + variance normalized) feature shape=', (1196, 13))\n",
      "('mfcc feature cube shape=', (1196, 13, 3))\n",
      "('logenergy features=', (1196, 40))\n"
     ]
    }
   ],
   "source": [
    "import scipy.io.wavfile as wav\n",
    "import numpy as np\n",
    "import speechpy\n",
    "import os\n",
    "\n",
    "file_name = 'Alesis-Sanctuary-QCard-AcoustcBas-C2.wav'\n",
    "fs, signal = wav.read(file_name)\n",
    "signal = signal[:,0]\n",
    "\n",
    "print(signal)\n",
    "print(type(signal))\n",
    "print(signal.shape)\n",
    "print(fs)\n",
    "\n",
    "# Example of pre-emphasizing.\n",
    "signal_preemphasized = speechpy.processing.preemphasis(signal, cof=0.98)\n",
    "\n",
    "# Example of staching frames\n",
    "frames = speechpy.processing.stack_frames(signal, sampling_frequency=fs, frame_length=0.020, frame_stride=0.01, filter=lambda x: np.ones((x,)),\n",
    "         zero_padding=True)\n",
    "\n",
    "print(frames.shape)\n",
    "\n",
    "# Example of extracting power spectrum\n",
    "power_spectrum = speechpy.processing.power_spectrum(frames, fft_points=512)\n",
    "print('power spectrum shape=', power_spectrum.shape)\n",
    "\n",
    "############# Extract MFCC features #############\n",
    "mfcc = speechpy.feature.mfcc(signal, sampling_frequency=fs, frame_length=0.020, frame_stride=0.01,\n",
    "             num_filters=40, fft_length=512, low_frequency=0, high_frequency=None)\n",
    "mfcc_cmvn = speechpy.processing.cmvnw(mfcc,win_size=301,variance_normalization=True)\n",
    "print('mfcc(mean + variance normalized) feature shape=', mfcc_cmvn.shape)\n",
    "\n",
    "mfcc_feature_cube = speechpy.feature.extract_derivative_feature(mfcc)\n",
    "print('mfcc feature cube shape=', mfcc_feature_cube.shape)\n",
    "\n",
    "############# Extract logenergy features #############\n",
    "logenergy = speechpy.feature.lmfe(signal, sampling_frequency=fs, frame_length=0.020, frame_stride=0.01,\n",
    "             num_filters=40, fft_length=512, low_frequency=0, high_frequency=None)\n",
    "logenergy_feature_cube = speechpy.feature.extract_derivative_feature(logenergy)\n",
    "print('logenergy features=', logenergy.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
