{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "from glob import glob\n",
    "import h5py\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.eager as tfe\n",
    "tfe.enable_eager_execution(device_policy=tfe.DEVICE_PLACEMENT_SILENT)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n"
     ]
    }
   ],
   "source": [
    "# xs = list()\n",
    "# ys = list()\n",
    "# seqs =list()\n",
    "\n",
    "# for i, fname in enumerate(glob(\"data_array/*.h5\")):\n",
    "#     print \n",
    "#     h5f = h5py.File(fname, 'r')\n",
    "#     xs.append(h5f['utterances'][:].astype(np.float32))\n",
    "#     ys.append(h5f['labels'][:])\n",
    "#     seqs.append(h5f['seqlen'][:])\n",
    "#     h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "xs = list()\n",
    "ys = list()\n",
    "seqs =list()\n",
    "\n",
    "for i, fname in enumerate(glob(\"data_array/*_0.h5\")):\n",
    "    print \n",
    "    h5f = h5py.File(fname, 'r')\n",
    "    xs.append(h5f['utterances'][:].astype(np.float32))\n",
    "    ys.append(h5f['labels'][:])\n",
    "    seqs.append(h5f['seqlen'][:])\n",
    "    h5f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs= np.concatenate(xs, axis=0).reshape(-1,30,20,40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-11.3272705 , -11.098531  , -12.024563  , -11.75084   ,\n",
       "        -11.995729  , -12.497992  , -11.672007  , -11.342683  ,\n",
       "        -13.097771  , -12.198968  , -10.037232  , -10.326045  ,\n",
       "        -11.89076   , -10.89288   , -11.749463  , -12.655762  ,\n",
       "        -13.074904  , -13.321461  , -12.401165  , -12.275452  ,\n",
       "        -11.910727  , -12.137964  , -13.357485  , -12.900663  ,\n",
       "        -12.503625  , -12.934339  , -12.407433  , -12.709288  ,\n",
       "        -12.9844265 , -14.044166  , -14.219702  , -13.603175  ,\n",
       "        -13.025263  , -13.892774  , -12.961201  , -12.502351  ,\n",
       "        -12.802773  , -12.380794  , -11.644626  , -10.282431  ],\n",
       "       [-10.781759  , -11.833653  , -12.305784  , -12.238375  ,\n",
       "        -14.576353  , -12.642482  , -11.823015  , -11.561551  ,\n",
       "        -11.314313  , -10.540486  , -10.579433  , -11.056011  ,\n",
       "        -11.325443  , -11.352741  , -11.894871  , -11.861593  ,\n",
       "        -12.109924  , -13.082043  , -12.779962  , -12.397122  ,\n",
       "        -11.788699  , -12.292261  , -12.996237  , -12.089271  ,\n",
       "        -12.077463  , -12.552897  , -12.312665  , -12.060684  ,\n",
       "        -12.958019  , -14.119037  , -14.15322   , -13.751942  ,\n",
       "        -13.747976  , -13.839363  , -13.5668125 , -13.104888  ,\n",
       "        -13.327195  , -12.668749  , -11.749208  , -11.1424265 ],\n",
       "       [ -9.382742  ,  -9.492805  ,  -9.213147  ,  -9.894708  ,\n",
       "        -10.7631645 , -11.159223  , -10.706634  , -11.431975  ,\n",
       "        -10.44796   , -11.287916  , -10.924692  , -12.604759  ,\n",
       "        -11.163182  , -11.228519  , -11.639132  , -12.232321  ,\n",
       "        -11.825199  , -11.617007  , -11.742984  , -11.5339985 ,\n",
       "        -12.017724  , -11.957586  , -12.278557  , -12.346698  ,\n",
       "        -12.3509    , -12.943385  , -12.898686  , -12.29922   ,\n",
       "        -13.893491  , -15.033342  , -14.29123   , -13.038363  ,\n",
       "        -12.717658  , -12.532724  , -12.982793  , -13.077018  ,\n",
       "        -12.781536  , -11.954719  , -11.486745  , -11.349214  ],\n",
       "       [ -8.781988  ,  -7.535967  ,  -7.6305137 ,  -9.725706  ,\n",
       "        -10.834698  , -11.859444  , -10.747267  , -10.40616   ,\n",
       "        -11.128353  , -10.996048  , -10.443885  , -10.919565  ,\n",
       "        -11.33172   , -12.745078  , -11.996125  , -12.211916  ,\n",
       "        -12.698896  , -11.744537  , -11.894949  , -11.750128  ,\n",
       "        -12.615646  , -11.97629   , -11.869239  , -12.45947   ,\n",
       "        -12.1010475 , -12.969344  , -12.876793  , -13.385914  ,\n",
       "        -13.277484  , -13.32928   , -13.223769  , -12.835936  ,\n",
       "        -11.564154  , -10.82327   , -11.242273  , -12.159437  ,\n",
       "        -11.395403  , -10.82948   , -11.016364  , -11.853423  ],\n",
       "       [ -8.038962  ,  -6.4340835 ,  -6.536256  ,  -8.341349  ,\n",
       "         -8.9427805 ,  -9.200281  , -10.616652  , -10.501087  ,\n",
       "        -10.048952  ,  -9.4452    ,  -9.225682  , -10.851501  ,\n",
       "        -10.314342  , -11.722143  , -12.637035  , -12.090402  ,\n",
       "        -11.412991  , -12.632683  , -12.605133  , -12.821078  ,\n",
       "        -12.017951  , -11.818927  , -11.398435  , -11.577199  ,\n",
       "        -11.17416   , -11.744256  , -12.012652  , -12.114524  ,\n",
       "        -11.972549  , -11.822201  , -11.454914  , -13.013342  ,\n",
       "        -11.163963  , -10.197673  , -11.222942  , -12.32567   ,\n",
       "        -10.995877  , -10.618477  , -11.245115  , -10.947782  ],\n",
       "       [ -6.58072   ,  -5.327318  ,  -5.6360617 ,  -7.640112  ,\n",
       "         -7.0099187 ,  -6.555117  ,  -7.108553  ,  -7.3652163 ,\n",
       "         -8.665722  ,  -7.597442  ,  -7.418471  ,  -7.8076563 ,\n",
       "         -9.073036  ,  -9.972354  , -10.117393  , -11.676588  ,\n",
       "        -10.628476  , -11.500198  , -12.761103  , -11.4642315 ,\n",
       "         -9.0998535 ,  -8.436117  , -10.003691  , -11.121266  ,\n",
       "        -10.3388    , -10.323221  , -10.956416  , -11.862788  ,\n",
       "        -10.945821  , -10.511797  , -10.971332  , -11.530546  ,\n",
       "        -10.967018  ,  -9.987643  , -10.721175  , -10.772996  ,\n",
       "        -10.85419   , -10.11881   ,  -9.878991  ,  -8.821529  ],\n",
       "       [ -6.8761983 ,  -4.7855983 ,  -4.7175274 ,  -6.5713716 ,\n",
       "         -6.457426  ,  -5.2723274 ,  -4.851315  ,  -4.1987104 ,\n",
       "         -3.9937768 ,  -4.6668725 ,  -4.999789  ,  -7.594176  ,\n",
       "         -7.176084  ,  -7.120754  ,  -7.449054  ,  -8.276299  ,\n",
       "         -8.788041  ,  -9.323511  ,  -9.4576845 ,  -8.687185  ,\n",
       "         -6.8346763 ,  -5.637369  ,  -6.908226  ,  -9.353888  ,\n",
       "         -9.882608  ,  -9.8364    , -10.704432  , -11.359757  ,\n",
       "        -10.776106  , -10.495759  , -10.887988  , -10.35592   ,\n",
       "        -10.299155  ,  -8.907035  , -10.228364  , -10.251852  ,\n",
       "        -10.545322  ,  -9.819534  ,  -9.229596  ,  -8.57051   ],\n",
       "       [ -7.7020793 ,  -4.445742  ,  -3.729417  ,  -5.870817  ,\n",
       "         -7.2926245 ,  -4.3464103 ,  -3.7885861 ,  -4.639652  ,\n",
       "         -2.560787  ,  -2.2101135 ,  -2.9383965 ,  -3.5927193 ,\n",
       "         -5.8152695 ,  -5.027878  ,  -6.027034  ,  -5.687988  ,\n",
       "         -6.395765  ,  -6.393485  ,  -6.8613787 ,  -6.81579   ,\n",
       "         -5.3919296 ,  -4.5166516 ,  -6.053429  ,  -7.0981054 ,\n",
       "         -7.115775  ,  -7.2160716 ,  -7.2589216 ,  -7.226853  ,\n",
       "         -7.1880236 ,  -7.200184  ,  -7.4400587 ,  -7.6255465 ,\n",
       "         -7.0465603 ,  -7.149939  ,  -7.6528163 ,  -8.230148  ,\n",
       "         -7.760599  ,  -7.118939  ,  -7.2094655 ,  -8.023934  ],\n",
       "       [ -6.4204044 ,  -4.534691  ,  -3.1942556 ,  -4.6637015 ,\n",
       "         -5.0921526 ,  -3.4181113 ,  -4.045243  ,  -4.3805804 ,\n",
       "         -2.1700907 ,  -2.164868  ,  -2.383211  ,  -1.7600249 ,\n",
       "         -4.2926745 ,  -3.7255268 ,  -4.66205   ,  -4.2108502 ,\n",
       "         -5.538391  ,  -6.159053  ,  -6.854081  ,  -6.987865  ,\n",
       "         -5.07299   ,  -4.1762753 ,  -6.1895704 ,  -6.3251514 ,\n",
       "         -6.771038  ,  -7.448577  ,  -8.578389  ,  -8.228941  ,\n",
       "         -7.9306045 ,  -7.9111333 ,  -8.839909  ,  -8.010645  ,\n",
       "         -6.3726177 ,  -6.2137537 ,  -7.2491    ,  -9.002833  ,\n",
       "         -7.1774178 ,  -6.1604867 ,  -6.368701  ,  -7.116757  ],\n",
       "       [ -6.6404786 ,  -4.333481  ,  -3.3505993 ,  -5.202291  ,\n",
       "         -5.778075  ,  -4.120728  ,  -3.985243  ,  -4.071562  ,\n",
       "         -2.626568  ,  -3.829111  ,  -1.8191411 ,  -1.0492382 ,\n",
       "         -3.7788272 ,  -3.5472167 ,  -4.22559   ,  -4.0487814 ,\n",
       "         -5.7297864 ,  -5.8341107 ,  -5.577809  ,  -5.0492764 ,\n",
       "         -4.6404896 ,  -4.329913  ,  -6.476873  ,  -7.5512886 ,\n",
       "         -7.1137614 ,  -7.564071  ,  -8.396726  ,  -8.083872  ,\n",
       "         -8.354892  ,  -8.40864   ,  -8.223974  ,  -8.10887   ,\n",
       "         -6.191724  ,  -5.9026294 ,  -7.5465198 ,  -7.7376776 ,\n",
       "         -6.8701386 ,  -6.25597   ,  -6.565758  ,  -7.036589  ],\n",
       "       [ -6.1827025 ,  -4.5833135 ,  -3.6041083 ,  -5.427698  ,\n",
       "         -5.809913  ,  -4.288437  ,  -4.493442  ,  -5.0331197 ,\n",
       "         -3.3461483 ,  -3.775188  ,  -1.2761437 ,  -0.6423826 ,\n",
       "         -3.7297447 ,  -3.483108  ,  -4.1997766 ,  -4.2243037 ,\n",
       "         -5.3665757 ,  -5.216327  ,  -5.836758  ,  -5.067681  ,\n",
       "         -4.3531027 ,  -5.168241  ,  -6.231871  ,  -6.765052  ,\n",
       "         -7.413377  ,  -7.4231424 ,  -7.821254  ,  -8.243719  ,\n",
       "         -8.250588  ,  -8.389962  ,  -8.498699  ,  -7.838113  ,\n",
       "         -6.3600483 ,  -5.5658817 ,  -6.9944763 ,  -7.3368077 ,\n",
       "         -6.08277   ,  -6.5062237 ,  -7.0074954 ,  -7.42957   ],\n",
       "       [ -6.048428  ,  -4.8473086 ,  -4.1237574 ,  -5.9062624 ,\n",
       "         -6.3072295 ,  -4.7530828 ,  -5.197871  ,  -6.430938  ,\n",
       "         -3.5700912 ,  -3.4965835 ,  -1.0846081 ,  -0.4542546 ,\n",
       "         -3.4295762 ,  -3.045515  ,  -4.4556327 ,  -4.008703  ,\n",
       "         -5.109916  ,  -5.523468  ,  -5.1717877 ,  -4.427017  ,\n",
       "         -3.9719152 ,  -6.268123  ,  -6.583174  ,  -7.2357326 ,\n",
       "         -7.614558  ,  -8.035089  ,  -8.604208  ,  -8.048925  ,\n",
       "         -8.537336  ,  -8.868532  ,  -8.875719  ,  -8.198453  ,\n",
       "         -6.3308854 ,  -5.685774  ,  -6.879469  ,  -7.5162845 ,\n",
       "         -6.050843  ,  -6.4382315 ,  -7.630732  ,  -7.943593  ],\n",
       "       [ -6.7111106 ,  -5.2492013 ,  -4.125192  ,  -6.200686  ,\n",
       "         -7.392729  ,  -5.263129  ,  -4.352243  ,  -5.0203743 ,\n",
       "         -3.8303735 ,  -3.888956  ,  -1.132378  ,  -0.39052284,\n",
       "         -3.142306  ,  -2.82697   ,  -4.788339  ,  -3.734398  ,\n",
       "         -5.972886  ,  -5.0756173 ,  -5.437313  ,  -4.630682  ,\n",
       "         -3.4463015 ,  -6.378869  ,  -6.985235  ,  -8.279965  ,\n",
       "         -8.675329  ,  -9.111493  ,  -9.07749   ,  -9.141278  ,\n",
       "         -9.851679  , -10.279996  ,  -9.868745  ,  -8.7994585 ,\n",
       "         -6.595453  ,  -5.5833464 ,  -7.0503016 ,  -7.540221  ,\n",
       "         -6.2609854 ,  -6.3285165 ,  -8.43829   ,  -8.595205  ],\n",
       "       [ -7.2235265 ,  -5.543389  ,  -4.4813275 ,  -6.182777  ,\n",
       "         -7.338267  ,  -5.6900153 ,  -5.13523   ,  -5.336854  ,\n",
       "         -4.1985397 ,  -4.3750725 ,  -1.4174874 ,  -0.47837093,\n",
       "         -2.9183836 ,  -2.6469374 ,  -4.955857  ,  -3.691135  ,\n",
       "         -6.197348  ,  -5.0710244 ,  -5.01886   ,  -4.8578005 ,\n",
       "         -3.5284183 ,  -5.6606574 ,  -6.151016  ,  -6.683534  ,\n",
       "         -6.937547  ,  -7.2986794 ,  -7.3575926 ,  -7.632074  ,\n",
       "         -7.5808606 ,  -7.543096  ,  -7.728207  ,  -7.5789347 ,\n",
       "         -6.933342  ,  -5.6767364 ,  -6.9590483 ,  -7.677304  ,\n",
       "         -6.90182   ,  -6.6754746 ,  -8.081551  ,  -7.831602  ],\n",
       "       [ -6.442332  ,  -5.2616463 ,  -4.476938  ,  -5.735322  ,\n",
       "         -6.119904  ,  -5.310832  ,  -6.376016  ,  -5.2459087 ,\n",
       "         -4.546574  ,  -5.4684052 ,  -1.697688  ,  -0.67397887,\n",
       "         -3.6211636 ,  -2.868524  ,  -4.1389656 ,  -3.840681  ,\n",
       "         -4.5028143 ,  -5.168028  ,  -4.64003   ,  -4.576907  ,\n",
       "         -4.1842093 ,  -6.155851  ,  -6.765198  ,  -7.2846622 ,\n",
       "         -7.428361  ,  -7.9147553 ,  -8.563087  ,  -9.416575  ,\n",
       "         -9.50871   ,  -9.219421  ,  -8.921559  ,  -8.526023  ,\n",
       "         -7.6355615 ,  -5.68415   ,  -6.937937  ,  -7.863961  ,\n",
       "         -7.1873097 ,  -6.940154  ,  -8.330738  ,  -8.858081  ],\n",
       "       [ -8.099426  ,  -6.3460126 ,  -4.4760222 ,  -5.2852263 ,\n",
       "         -6.5987864 ,  -6.1885886 ,  -4.856519  ,  -5.401514  ,\n",
       "         -4.686297  ,  -4.9645133 ,  -2.1404798 ,  -0.7279802 ,\n",
       "         -3.4775152 ,  -3.1824214 ,  -3.3389769 ,  -3.5679002 ,\n",
       "         -5.161677  ,  -5.3928556 ,  -5.4349813 ,  -4.1675467 ,\n",
       "         -4.8093367 ,  -5.7849    ,  -6.4659142 ,  -6.9740705 ,\n",
       "         -7.438864  ,  -7.134485  ,  -7.6472044 ,  -7.7455344 ,\n",
       "         -7.7905946 ,  -8.007987  ,  -8.118774  ,  -7.7471414 ,\n",
       "         -7.3360634 ,  -6.0373144 ,  -6.993803  ,  -7.5127034 ,\n",
       "         -7.1366034 ,  -7.2034907 ,  -8.302697  ,  -8.546204  ],\n",
       "       [ -6.101537  ,  -5.5700493 ,  -4.544193  ,  -5.756038  ,\n",
       "         -6.4915943 ,  -5.822806  ,  -5.117006  ,  -5.5817556 ,\n",
       "         -4.8365264 ,  -4.368904  ,  -2.5198114 ,  -0.8943429 ,\n",
       "         -3.1909657 ,  -3.3140311 ,  -3.2764726 ,  -3.625517  ,\n",
       "         -4.6513295 ,  -4.9386196 ,  -5.0250516 ,  -4.4357557 ,\n",
       "         -5.586578  ,  -5.6792    ,  -7.191696  ,  -7.8459244 ,\n",
       "         -7.50396   ,  -8.695284  ,  -8.089962  ,  -8.842621  ,\n",
       "         -8.58207   ,  -8.929065  ,  -8.835217  ,  -8.852124  ,\n",
       "         -7.6839943 ,  -6.9035163 ,  -7.3688364 ,  -8.116419  ,\n",
       "         -7.2596135 ,  -7.1414423 ,  -8.8296385 ,  -9.183438  ],\n",
       "       [ -6.283319  ,  -5.6237993 ,  -4.445297  ,  -5.996758  ,\n",
       "         -7.0751543 ,  -6.0552096 ,  -6.1668973 ,  -7.822886  ,\n",
       "         -5.696336  ,  -4.007063  ,  -2.7838612 ,  -0.96442354,\n",
       "         -2.9906526 ,  -3.0751593 ,  -3.998681  ,  -4.0292544 ,\n",
       "         -4.5880427 ,  -5.3554454 ,  -4.626404  ,  -3.9607859 ,\n",
       "         -5.1018744 ,  -6.2203193 ,  -7.835204  ,  -7.9142337 ,\n",
       "         -8.259319  ,  -8.2899275 ,  -8.829049  ,  -9.087702  ,\n",
       "         -9.189704  ,  -9.2023325 ,  -9.330194  ,  -8.977301  ,\n",
       "         -7.69072   ,  -6.664292  ,  -7.1838536 ,  -8.570126  ,\n",
       "         -7.055846  ,  -7.046996  ,  -9.237049  ,  -9.621281  ],\n",
       "       [ -6.6612167 ,  -5.9772925 ,  -4.638947  ,  -6.1925106 ,\n",
       "         -7.6707873 ,  -6.6308317 ,  -5.636828  ,  -7.159299  ,\n",
       "         -5.037171  ,  -4.205015  ,  -2.5947118 ,  -0.93687797,\n",
       "         -2.996148  ,  -2.9081867 ,  -4.4422984 ,  -3.70714   ,\n",
       "         -5.251451  ,  -5.8026295 ,  -4.7095227 ,  -4.161533  ,\n",
       "         -4.3489127 ,  -6.0551248 ,  -7.9331837 ,  -7.9944406 ,\n",
       "         -8.7983885 ,  -8.759074  ,  -9.655331  , -10.288923  ,\n",
       "        -10.282771  , -10.530825  , -10.145246  ,  -9.494253  ,\n",
       "         -7.7093544 ,  -6.2174997 ,  -7.1148405 ,  -8.20043   ,\n",
       "         -6.717437  ,  -6.91225   ,  -9.564948  ,  -9.935297  ],\n",
       "       [ -7.6367993 ,  -6.056832  ,  -4.987115  ,  -6.5147877 ,\n",
       "         -7.8855753 ,  -6.4694853 ,  -6.295025  ,  -6.615682  ,\n",
       "         -4.546436  ,  -4.7261214 ,  -2.32147   ,  -1.2364994 ,\n",
       "         -3.3761528 ,  -2.648812  ,  -4.4908037 ,  -3.9699054 ,\n",
       "         -5.5264754 ,  -6.878256  ,  -4.6482615 ,  -4.612872  ,\n",
       "         -3.9404604 ,  -5.492744  ,  -6.4480433 ,  -6.665613  ,\n",
       "         -7.0668054 ,  -7.2033715 ,  -7.465096  ,  -7.5733614 ,\n",
       "         -7.7324204 ,  -7.675418  ,  -7.6347513 ,  -7.707375  ,\n",
       "         -7.0337176 ,  -5.9412446 ,  -7.204073  ,  -7.4258966 ,\n",
       "         -6.618312  ,  -7.0286846 ,  -8.680357  ,  -9.075494  ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs[0,0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs2 = np.rollaxis(xs, 1, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = xs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys= np.concatenate(ys, axis=0).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "seqs= np.concatenate(seqs, axis=0).reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3311, 20, 40, 30)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3311,)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "ys = np.eye(30,30)[ys]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1.])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3311,)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs_train, xs_test, ys_train, ys_test, seqs_train, seqs_test = train_test_split(xs, ys, seqs, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "del xs, ys, seqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2218, 20, 40, 30)"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = tf.data.Dataset.from_tensor_slices((xs_train, ys_train)).shuffle(buffer_size=10000).batch(32)\n",
    "ds_test = tf.data.Dataset.from_tensor_slices((xs_test, ys_test)).shuffle(buffer_size=10000).batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper parameters\n",
    "LEARNING_RATE = 0.5\n",
    "\n",
    "layers = tf.keras.layers\n",
    "\n",
    "\n",
    "class _IdentityBlock(tf.keras.Model):\n",
    "    \"\"\"_IdentityBlock is the block that has no conv layer at shortcut.\n",
    "    Args:\n",
    "      kernel_size: the kernel size of middle conv layer at main path\n",
    "      filters: list of integers, the filters of 3 conv layer at main path\n",
    "      stage: integer, current stage label, used for generating layer names\n",
    "      block: 'a','b'..., current block label, used for generating layer names\n",
    "      data_format: data_format for the input ('channels_first' or\n",
    "        'channels_last').\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, kernel_size, filters, stage, block):\n",
    "        super(_IdentityBlock, self).__init__(name='')\n",
    "        filters1, filters2, filters3 = filters\n",
    "\n",
    "        conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "        bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "        bn_axis = 3\n",
    "\n",
    "        self.conv2a = layers.Conv2D(\n",
    "            filters1, (1, 1), name=conv_name_base + '2a')\n",
    "        self.bn2a = layers.BatchNormalization(\n",
    "            axis=bn_axis, name=bn_name_base + '2a')\n",
    "\n",
    "        self.conv2b = layers.Conv2D(\n",
    "            filters2,\n",
    "            kernel_size,\n",
    "            padding='same',\n",
    "            name=conv_name_base + '2b')\n",
    "        self.bn2b = layers.BatchNormalization(\n",
    "            axis=bn_axis, name=bn_name_base + '2b')\n",
    "\n",
    "        self.conv2c = layers.Conv2D(\n",
    "            filters3, (1, 1), name=conv_name_base + '2c')\n",
    "        self.bn2c = layers.BatchNormalization(\n",
    "            axis=bn_axis, name=bn_name_base + '2c')\n",
    "\n",
    "    def __call__(self, input_tensor, training=False):\n",
    "        return self.call(input_tensor=input_tensor, training=training)\n",
    "\n",
    "    def call(self, input_tensor, training=False):\n",
    "        x = self.conv2a(input_tensor)\n",
    "        x = self.bn2a(x, training=training)\n",
    "        x = tf.nn.relu(x)\n",
    "\n",
    "        x = self.conv2b(x)\n",
    "        x = self.bn2b(x, training=training)\n",
    "        x = tf.nn.relu(x)\n",
    "\n",
    "        x = self.conv2c(x)\n",
    "        x = self.bn2c(x, training=training)\n",
    "\n",
    "        x += input_tensor\n",
    "        return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "class _ConvBlock(tf.keras.Model):\n",
    "    \"\"\"_ConvBlock is the block that has a conv layer at shortcut.\n",
    "    Args:\n",
    "        kernel_size: the kernel size of middle conv layer at main path\n",
    "        filters: list of integers, the filters of 3 conv layer at main path\n",
    "        stage: integer, current stage label, used for generating layer names\n",
    "        block: 'a','b'..., current block label, used for generating layer names\n",
    "        data_format: data_format for the input ('channels_first' or\n",
    "          'channels_last').\n",
    "        strides: strides for the convolution. Note that from stage 3, the first\n",
    "         conv layer at main path is with strides=(2,2), and the shortcut should\n",
    "         have strides=(2,2) as well.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 kernel_size,\n",
    "                 filters,\n",
    "                 stage,\n",
    "                 block,\n",
    "                 strides=(2, 2)):\n",
    "        super(_ConvBlock, self).__init__(name='')\n",
    "        filters1, filters2, filters3 = filters\n",
    "\n",
    "        conv_name_base = 'res' + str(stage) + block + '_branch'\n",
    "        bn_name_base = 'bn' + str(stage) + block + '_branch'\n",
    "        bn_axis = 3\n",
    "\n",
    "        self.conv2a = layers.Conv2D(\n",
    "            filters1, (1, 1),\n",
    "            strides=strides,\n",
    "            name=conv_name_base + '2a')\n",
    "\n",
    "        self.bn2a = layers.BatchNormalization(\n",
    "            axis=bn_axis, name=bn_name_base + '2a')\n",
    "\n",
    "        self.conv2b = layers.Conv2D(\n",
    "            filters2,\n",
    "            kernel_size,\n",
    "            padding='same',\n",
    "            name=conv_name_base + '2b')\n",
    "\n",
    "        self.bn2b = layers.BatchNormalization(\n",
    "            axis=bn_axis, name=bn_name_base + '2b')\n",
    "\n",
    "        self.conv2c = layers.Conv2D(\n",
    "            filters3, (1, 1), name=conv_name_base + '2c')\n",
    "        self.bn2c = layers.BatchNormalization(\n",
    "            axis=bn_axis, name=bn_name_base + '2c')\n",
    "\n",
    "        self.conv_shortcut = layers.Conv2D(\n",
    "            filters3, (1, 1),\n",
    "            strides=strides,\n",
    "            name=conv_name_base + '1')\n",
    "\n",
    "        self.bn_shortcut = layers.BatchNormalization(\n",
    "            axis=bn_axis, name=bn_name_base + '1')\n",
    "\n",
    "    def __call__(self, input_tensor, training=False):\n",
    "        return self.call(input_tensor=input_tensor, training=training)\n",
    "\n",
    "    def call(self, input_tensor, training=False):\n",
    "        x = self.conv2a(input_tensor)\n",
    "        x = self.bn2a(x, training=training)\n",
    "        x = tf.nn.relu(x)\n",
    "\n",
    "        x = self.conv2b(x)\n",
    "        x = self.bn2b(x, training=training)\n",
    "        x = tf.nn.relu(x)\n",
    "\n",
    "        x = self.conv2c(x)\n",
    "        x = self.bn2c(x, training=training)\n",
    "\n",
    "        shortcut = self.conv_shortcut(input_tensor)\n",
    "        shortcut = self.bn_shortcut(shortcut, training=training)\n",
    "\n",
    "        x += shortcut\n",
    "        return tf.nn.relu(x)\n",
    "\n",
    "\n",
    "class DVectorNet(tf.keras.Model):\n",
    "    def __init__(self, input_dim, out_dim, checkpoint_directory, batch_size=32, device_name=\"cpu:0\"):\n",
    "        super(DVectorNet, self).__init__()\n",
    "\n",
    "        self.input_dim = input_dim\n",
    "        self.out_dim = out_dim\n",
    "        self.checkpoint_directory = checkpoint_directory\n",
    "        self.batch_size = batch_size\n",
    "        self.device_name = device_name\n",
    "\n",
    "        def conv_block(filters, stage, block, strides=(2, 2)):\n",
    "            return _ConvBlock(\n",
    "                3,\n",
    "                filters,\n",
    "                stage=stage,\n",
    "                block=block,\n",
    "                strides=strides)\n",
    "\n",
    "        def id_block(filters, stage, block):\n",
    "            return _IdentityBlock(\n",
    "                3, filters, stage=stage, block=block)\n",
    "\n",
    "        self.conv1 = layers.Conv2D(\n",
    "            64, (7, 7),\n",
    "            strides=(2, 2),\n",
    "            padding='same',\n",
    "            name='conv1')\n",
    "\n",
    "        bn_axis = 3\n",
    "\n",
    "        self.bn_conv1 = layers.BatchNormalization(axis=bn_axis, name='bn_conv1')\n",
    "        self.max_pool = layers.MaxPooling2D(\n",
    "            (3, 3), strides=(2, 2))\n",
    "\n",
    "        self.l2a = conv_block([64, 64, 256], stage=2, block='a', strides=(1, 1))\n",
    "        self.l2b = id_block([64, 64, 256], stage=2, block='b')\n",
    "        self.l2c = id_block([64, 64, 256], stage=2, block='c')\n",
    "\n",
    "        self.l3a = conv_block([128, 128, 512], stage=3, block='a')\n",
    "        self.l3b = id_block([128, 128, 512], stage=3, block='b')\n",
    "        self.l3c = id_block([128, 128, 512], stage=3, block='c')\n",
    "        self.l3d = id_block([128, 128, 512], stage=3, block='d')\n",
    "\n",
    "        self.l4a = conv_block([256, 256, 1024], stage=4, block='a')\n",
    "        self.l4b = id_block([256, 256, 1024], stage=4, block='b')\n",
    "        self.l4c = id_block([256, 256, 1024], stage=4, block='c')\n",
    "        self.l4d = id_block([256, 256, 1024], stage=4, block='d')\n",
    "        self.l4e = id_block([256, 256, 1024], stage=4, block='e')\n",
    "        self.l4f = id_block([256, 256, 1024], stage=4, block='f')\n",
    "\n",
    "        self.l5a = conv_block([512, 512, 2048], stage=5, block='a')\n",
    "        self.l5b = id_block([512, 512, 2048], stage=5, block='b')\n",
    "        self.l5c = id_block([512, 512, 2048], stage=5, block='c')\n",
    "\n",
    "        self.avg_pool = layers.AveragePooling2D(\n",
    "            (7, 7), strides=(7, 7))\n",
    "\n",
    "        self.flatten = layers.Flatten()\n",
    "        self.dvector = layers.Dense(2048, name='dvector', activation=tf.nn.relu)\n",
    "        self.fc1000 = layers.Dense(out_dim, name='fc1000', activation=tf.nn.softmax)\n",
    "\n",
    "        self.optimizer = tf.train.AdamOptimizer(learning_rate=LEARNING_RATE)\n",
    "\n",
    "    def call(self, input_tensor, training=False):\n",
    "        x = self.conv1(input_tensor)\n",
    "        x = self.bn_conv1(x, training=training)\n",
    "\n",
    "        x = tf.nn.relu(x)\n",
    "        x = self.max_pool(x)\n",
    "\n",
    "        x = self.l2a(x, training=training)\n",
    "        x = self.l2b(x, training=training)\n",
    "        x = self.l2c(x, training=training)\n",
    "\n",
    "        x = self.l3a(x, training=training)\n",
    "        x = self.l3b(x, training=training)\n",
    "        x = self.l3c(x, training=training)\n",
    "        x = self.l3d(x, training=training)\n",
    "\n",
    "        x = self.l4a(x, training=training)\n",
    "        x = self.l4b(x, training=training)\n",
    "        x = self.l4c(x, training=training)\n",
    "        x = self.l4d(x, training=training)\n",
    "        x = self.l4e(x, training=training)\n",
    "        x = self.l4f(x, training=training)\n",
    "\n",
    "        x = self.l5a(x, training=training)\n",
    "        x = self.l5b(x, training=training)\n",
    "        x = self.l5c(x, training=training)\n",
    "\n",
    "        x = self.avg_pool(x)\n",
    "        x = self.dvector(self.flatten(x))\n",
    "\n",
    "        x = self.fc1000(x)\n",
    "        return x\n",
    "\n",
    "    def loss(self, input_tensor, target, training=False):\n",
    "        predictions = self.call(input_tensor, training=training)\n",
    "        loss_value = tf.losses.softmax_cross_entropy(logits=predictions, onehot_labels=target)\n",
    "        self.loss_sum+=loss_value\n",
    "        return loss_value\n",
    "\n",
    "    def grads(self, input_tensor, target, training=False):\n",
    "        with tfe.GradientTape() as tape:\n",
    "            loss_value = self.loss(input_tensor, target, training=training)\n",
    "        return tape.gradient(loss_value, self.variables)\n",
    "\n",
    "    def fit(self,\n",
    "            train_data=None,\n",
    "            eval_data=None,\n",
    "            batch_size=None,\n",
    "            epochs=500,\n",
    "            verbose=1,\n",
    "            callbacks=None,\n",
    "            validation_split=0.,\n",
    "            validation_data=None,\n",
    "            shuffle=True,\n",
    "            class_weight=None,\n",
    "            sample_weight=None,\n",
    "            initial_epoch=0,\n",
    "            steps_per_epoch=None,\n",
    "            validation_steps=None,\n",
    "            **kwargs):\n",
    "\n",
    "        train_acc = tfe.metrics.Accuracy('train_acc')\n",
    "        eval_acc = tfe.metrics.Accuracy('eval_acc')\n",
    "\n",
    "        self.history = {}\n",
    "        self.history['train_acc'] = []\n",
    "        self.history['eval_acc'] = []\n",
    "\n",
    "        with tf.device(self.device_name):\n",
    "            for i in range(epochs):\n",
    "                self.loss_sum = 0\n",
    "                for X, y in tfe.Iterator(train_data):\n",
    "                    grads = self.grads(input_tensor=X, target=y, training=True)\n",
    "                    self.optimizer.apply_gradients(zip(grads, self.variables))\n",
    "                for X, y in tfe.Iterator(train_data):\n",
    "                    logits = self.call(input_tensor=X, training=False)\n",
    "                    preds = tf.argmax(logits, axis=1)\n",
    "                    li.append(np.argmax(y,axis=1))\n",
    "\n",
    "                    train_acc(preds, np.argmax(y, axis=1))\n",
    "                self.history['train_acc'].append(train_acc.result().numpy())\n",
    "\n",
    "                train_acc.init_variables()\n",
    "\n",
    "                # Check accuracy eval dataset\n",
    "                for X, y in tfe.Iterator(eval_data):\n",
    "                    logits = self.call(input_tensor=X, training=False)\n",
    "                    preds = tf.argmax(logits, axis=1)\n",
    "                    eval_acc(preds, np.argmax(y, axis=1))\n",
    "                self.history['eval_acc'].append(eval_acc.result().numpy())\n",
    "                # Reset metrics\n",
    "                eval_acc.init_variables()\n",
    "\n",
    "                if (i == 0) | ((i + 1) % verbose == 0):\n",
    "                    print('Train accuracy at epoch %d: ' % (i + 1), self.history['train_acc'][-1])\n",
    "                    print('Eval accuracy at epoch %d: ' % (i + 1), self.history['eval_acc'][-1])\n",
    "                    print('Loss : %s' % self.loss_sum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "dn = DVectorNet((800,), 30, \"./\", device_name=\"gpu:0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dn.fit(ds_train, ds_test, epochs=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
